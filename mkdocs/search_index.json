{
    "docs": [
        {
            "location": "/",
            "text": "Woofer: logging in (best) practice(s)\n\n\nThis projects is a showcase web app that demonstrates both \nlogging best practices\n (based on our \n\norange-mathoms-logging\n library), as well as providing a \nquite advanced \nSpring Boot-based microservices project sample\n.\n\n\n\n\nWhat is Woofer ?\n\n\nWoofer is meant to be a basic clone of \nTweeter\n.\n\n\nIt allows anyone to create an account, post short messages (aka \nwoofs\n), subscribe and unsubscribe to other\nusers woofs...\n\n\nRun it on your computer\n\n\nYou may clone the project from GitHub, then as any Spring Boot application, each Woofer service may be launched on your \ncomputer with:\n\n\nmvn spring-boot:run\n\n\n\n\nYou'll then be able to access Woofer's pages on \nyour computer\n...\n\n\n\n\nYou may either \ncreate your own account\n, or use any of the \nexisting accounts\n\n(each one having the \nuser\n password).\n\n\n\n\nLicense\n\n\nWoofer's code is under \nApache-2.0 License\n\n\nTry it !\n\n\nNotice that even if your app is not in microservices architecture, the Woofer demo has plenty of great stuff to discover !",
            "title": "Home"
        },
        {
            "location": "/#woofer-logging-in-best-practices",
            "text": "This projects is a showcase web app that demonstrates both  logging best practices  (based on our  orange-mathoms-logging  library), as well as providing a \nquite advanced  Spring Boot-based microservices project sample .",
            "title": "Woofer: logging in (best) practice(s)"
        },
        {
            "location": "/#what-is-woofer",
            "text": "Woofer is meant to be a basic clone of  Tweeter .  It allows anyone to create an account, post short messages (aka  woofs ), subscribe and unsubscribe to other\nusers woofs...",
            "title": "What is Woofer ?"
        },
        {
            "location": "/#run-it-on-your-computer",
            "text": "You may clone the project from GitHub, then as any Spring Boot application, each Woofer service may be launched on your \ncomputer with:  mvn spring-boot:run  You'll then be able to access Woofer's pages on  your computer ...   You may either  create your own account , or use any of the  existing accounts \n(each one having the  user  password).",
            "title": "Run it on your computer"
        },
        {
            "location": "/#license",
            "text": "Woofer's code is under  Apache-2.0 License",
            "title": "License"
        },
        {
            "location": "/#try-it",
            "text": "Notice that even if your app is not in microservices architecture, the Woofer demo has plenty of great stuff to discover !",
            "title": "Try it !"
        },
        {
            "location": "/spring-boot/",
            "text": "Spring & Spring Boot stuff\n\n\nWoofer was originally designed to be a showcase web app to demonstrate and enforce \nlogging best practices\n.\n\n\nBut actually it is also a quite advanced \nSpring Boot-based microservices project sample\n that could be used as a\nbootstrap to create a microservices application.\n\n\nThis page highlights Spring & Spring Boot modules used in Woofer.\n\n\n\n\nWoofer's microservices\n\n\nWoofer heavily relies on \nSpring Boot\n, and \nSpring Cloud\n to \nimplement a microservices architecture.\n\n\nIt involves the following components:\n\n\n\n\nservice-registry\n: the service registry server, basically implemented by \nEureka Server\n.\n\n\nrouter\n: a router and load balancer service, basically implemented by \nZuul\n;\n  only required if you want to load balance the \nwoofer-webfront\n service.\n\n\nwoofer-webfront\n: this is the web front-end application, that the end-user will use to connect, read and post woofs.\n\n\nwoofer-backend\n: this is the backend service, a pure JSON/Rest API service, that is consumed by the \nwoofer-webfront\n and possibly mobile apps (not part of the demo).\n\n\nwoofer-notifier\n: this is a notification service, that is asynchronously triggered when domain events occur (a user posts a woof, or subscribes/unsubscribes to a mate).\n  It is called asynchronously by \nwoofer-backend\n.\n\n\ndatabase: a basic \nMariaDB\n instance\n\n\nlogs centralization system: an \nELK\n instance \n\n\ndistributed tracing system: a basic \nZipkin\n server.\n\n\n\n\n\n\nWoofer's profiles\n\n\nBy default, when launching Woofer services locally with no profile, it will \nuse a memory database (\nh2\n),\noutput Java and Http logs to the console.\n\n\nBut Woofer has several Spring Boot \nprofiles\n\nto adapt to several environments.\n\n\n\n\n\n\n\n\nProfile\n\n\nDescription\n\n\nRequired environment variables\n\n\n\n\n\n\n\n\n\n\nlogstash\n\n\nused to ship Java and Http logs to a \nLogstash\n server in JSON native format\n\n\n$LOGSTASH_HOST\n, \n$LOGSTASH_PORT\n and optionally \n$MD_PROJECT\n \n(project ID metadata)\n\n\n\n\n\n\nh2\n\n\nuses \nh2\n as database (mem or file)\n\n\n$H2_DATASOURCE_URL\n (default in memory), \n$H2_USER\n (default \nsa\n) and \n$H2_PASSWORD\n (default none)\n\n\n\n\n\n\nmysql\n\n\nuses \nMySQL\n or \nMariaDB\n as database\n\n\n$MYSQL_DATASOURCE_URL\n (default on \nlocalhost\n), \n$MYSQL_USER\n (default \nroot\n) and \n$MYSQL_PASSWORD\n (default none)\n\n\n\n\n\n\nzipkin\n\n\nactivates distributed tracing with a \nZipkin\n server\n\n\n$ZIPKIN_URL\n and \n$ZIPKIN_SAMPLING\n (a ratio)\n\n\n\n\n\n\nopenshift\n\n\nadapts the Woofer configuration to an OpenShift v3 environment (work in progress)\n\n\nnone\n\n\n\n\n\n\njmx\n\n\nexposes Spring Boot Actuator \nmetrics\n through JMX\n\n\nnone\n\n\n\n\n\n\n\n\n\n\nSpring Data JPA\n\n\nSpring Data JPA\n is used to implement our Object-Relational Mapping (ORM).\n\n\nIt allows creating Data Access Objects (called \nRespositories\n in Spring terminology) simply by annotations and interfaces.\n\n\nSee:\n\n\n\n\nUserRepository.java\n\n\nWoofRepository.java\n\n\n\n\n\n\nSpring Data Rest\n\n\nSpring Data Rest\n is used to build hypermedia-driven REST web services on \ntop of Spring Data repositories.\n\n\nWoofer also uses the \nProjections\n\nfeature.\n\n\nSee:\n\n\n\n\nUser.java\n\n\nWoof.java\n\n\n\n\n\n\nSpring Cloud Netflix\n\n\nSpring Cloud Netflix\n is a great contribution from Netflix, that embeds \nseveral features to build cloud applications.\n\n\nEureka\n\n\nEureka server & client provides a very cheap and robust way of implementing \nservices registration and discovery\n in \na microservices architecture (\nmore info\n).\n\n\nIts use is quite straightforward as it only requires adding the right dependency to your \npom.xml\n, and a basic\nannotation to your Sprint Boot application (either  \n@EnableEurekaClient\n or \n@EnableEurekaServer\n).\n\n\nFeign\n\n\nFeign\n allows implementing \ndeclarative REST clients\n (i.e. through interfaces & annotations).\n\n\nIt is used in \nwoofer-webfront\n to implement the \nwoofer-backend\n REST client.\n\n\nSee:\n\n\n\n\nUsersClient.java\n\n\nWoofsClient.java\n\n\n\n\nRibbon\n\n\nRibbon provides \nclient side load balancer\n.\n\n\nIts use is quite straightforward as it only requires adding the right dependency to your \npom.xml\n.\n\n\n\n\nSpring Boot Actuator\n\n\nSpring Boot Actuator\n provides a set of tools\nto monitor and manage your application.\n\n\nApart from default management endpoints, \nwoofer-webfront\n and \nwoofer-backend\n publish some business metrics to count active\nsessions, woofs and subscriptions.\n\n\nSee:\n\n\n\n\nHomeController.java\n\n\nLoggedInUsersService.java\n\n\n\n\n\n\nSpring REST Docs\n\n\nSpring REST Docs\n is a tool for generating part of REST API documentation.\n\n\nIt is used in \nwoofer-backend\n project to generate the reference API documentation.\n\n\nSee:\n\n\n\n\napi-guide.adoc\n\n\nApiDocumentation.java\n\n\n\n\n\n\nSpring Cloud Sleuth\n\n\nSpring Cloud Sleuth\n is used for distributed tracing & logs correlation\n(see \nLogging - Code\n page for more details).",
            "title": "Spring Boot"
        },
        {
            "location": "/spring-boot/#spring-spring-boot-stuff",
            "text": "Woofer was originally designed to be a showcase web app to demonstrate and enforce  logging best practices .  But actually it is also a quite advanced  Spring Boot-based microservices project sample  that could be used as a\nbootstrap to create a microservices application.  This page highlights Spring & Spring Boot modules used in Woofer.",
            "title": "Spring &amp; Spring Boot stuff"
        },
        {
            "location": "/spring-boot/#woofers-microservices",
            "text": "Woofer heavily relies on  Spring Boot , and  Spring Cloud  to \nimplement a microservices architecture.  It involves the following components:   service-registry : the service registry server, basically implemented by  Eureka Server .  router : a router and load balancer service, basically implemented by  Zuul ;\n  only required if you want to load balance the  woofer-webfront  service.  woofer-webfront : this is the web front-end application, that the end-user will use to connect, read and post woofs.  woofer-backend : this is the backend service, a pure JSON/Rest API service, that is consumed by the  woofer-webfront  and possibly mobile apps (not part of the demo).  woofer-notifier : this is a notification service, that is asynchronously triggered when domain events occur (a user posts a woof, or subscribes/unsubscribes to a mate).\n  It is called asynchronously by  woofer-backend .  database: a basic  MariaDB  instance  logs centralization system: an  ELK  instance   distributed tracing system: a basic  Zipkin  server.",
            "title": "Woofer's microservices"
        },
        {
            "location": "/spring-boot/#woofers-profiles",
            "text": "By default, when launching Woofer services locally with no profile, it will \nuse a memory database ( h2 ),\noutput Java and Http logs to the console.  But Woofer has several Spring Boot  profiles \nto adapt to several environments.     Profile  Description  Required environment variables      logstash  used to ship Java and Http logs to a  Logstash  server in JSON native format  $LOGSTASH_HOST ,  $LOGSTASH_PORT  and optionally  $MD_PROJECT   (project ID metadata)    h2  uses  h2  as database (mem or file)  $H2_DATASOURCE_URL  (default in memory),  $H2_USER  (default  sa ) and  $H2_PASSWORD  (default none)    mysql  uses  MySQL  or  MariaDB  as database  $MYSQL_DATASOURCE_URL  (default on  localhost ),  $MYSQL_USER  (default  root ) and  $MYSQL_PASSWORD  (default none)    zipkin  activates distributed tracing with a  Zipkin  server  $ZIPKIN_URL  and  $ZIPKIN_SAMPLING  (a ratio)    openshift  adapts the Woofer configuration to an OpenShift v3 environment (work in progress)  none    jmx  exposes Spring Boot Actuator  metrics  through JMX  none",
            "title": "Woofer's profiles"
        },
        {
            "location": "/spring-boot/#spring-data-jpa",
            "text": "Spring Data JPA  is used to implement our Object-Relational Mapping (ORM).  It allows creating Data Access Objects (called  Respositories  in Spring terminology) simply by annotations and interfaces.  See:   UserRepository.java  WoofRepository.java",
            "title": "Spring Data JPA"
        },
        {
            "location": "/spring-boot/#spring-data-rest",
            "text": "Spring Data Rest  is used to build hypermedia-driven REST web services on \ntop of Spring Data repositories.  Woofer also uses the  Projections \nfeature.  See:   User.java  Woof.java",
            "title": "Spring Data Rest"
        },
        {
            "location": "/spring-boot/#spring-cloud-netflix",
            "text": "Spring Cloud Netflix  is a great contribution from Netflix, that embeds \nseveral features to build cloud applications.",
            "title": "Spring Cloud Netflix"
        },
        {
            "location": "/spring-boot/#eureka",
            "text": "Eureka server & client provides a very cheap and robust way of implementing  services registration and discovery  in \na microservices architecture ( more info ).  Its use is quite straightforward as it only requires adding the right dependency to your  pom.xml , and a basic\nannotation to your Sprint Boot application (either   @EnableEurekaClient  or  @EnableEurekaServer ).",
            "title": "Eureka"
        },
        {
            "location": "/spring-boot/#feign",
            "text": "Feign  allows implementing  declarative REST clients  (i.e. through interfaces & annotations).  It is used in  woofer-webfront  to implement the  woofer-backend  REST client.  See:   UsersClient.java  WoofsClient.java",
            "title": "Feign"
        },
        {
            "location": "/spring-boot/#ribbon",
            "text": "Ribbon provides  client side load balancer .  Its use is quite straightforward as it only requires adding the right dependency to your  pom.xml .",
            "title": "Ribbon"
        },
        {
            "location": "/spring-boot/#spring-boot-actuator",
            "text": "Spring Boot Actuator  provides a set of tools\nto monitor and manage your application.  Apart from default management endpoints,  woofer-webfront  and  woofer-backend  publish some business metrics to count active\nsessions, woofs and subscriptions.  See:   HomeController.java  LoggedInUsersService.java",
            "title": "Spring Boot Actuator"
        },
        {
            "location": "/spring-boot/#spring-rest-docs",
            "text": "Spring REST Docs  is a tool for generating part of REST API documentation.  It is used in  woofer-backend  project to generate the reference API documentation.  See:   api-guide.adoc  ApiDocumentation.java",
            "title": "Spring REST Docs"
        },
        {
            "location": "/spring-boot/#spring-cloud-sleuth",
            "text": "Spring Cloud Sleuth  is used for distributed tracing & logs correlation\n(see  Logging - Code  page for more details).",
            "title": "Spring Cloud Sleuth"
        },
        {
            "location": "/recommendations/",
            "text": "Logging in Java\n\n\nThis article has been written by Orange Software Expert members\n(see \nauthors\n), and is targeting Java (and JVM-based languages)\ndevelopers, and more specifically server-side developers (JEE or else).\n\n\nIt first gives a clear answer to \"which logging library should I use\", then gives\nseveral technical tips and tools to take the most benefit from your application logs.\n\n\nOur only goal is to share and spread best practices about logs.\n\n\n\n\nWhich logging library(ies)?\n\n\nIn Java, there are lots of logging libraries:\n\n\n\n\n\n\n\n\nLibrary\n\n\nComment\n\n\nOur advise\n\n\n\n\n\n\n\n\n\n\nutils.logging (aka JUL)\n\n\nFunctionally and technically, it lags behind competitors\n\n\ndo not use it\n\n\n\n\n\n\nLog4J 1\n\n\nToo old, not maintained anymore\n\n\ndo not use it\n\n\n\n\n\n\nApache commons-logging\n\n\nToo old, not maintained anymore\n\n\ndo not use it\n\n\n\n\n\n\nLog4J 2\n\n\nSeems okay, but clearly not very popular\n\n\nno concrete feedback for now\n\n\n\n\n\n\nSLF4J\n + \nlogback\n\n\nSee reasons below\n\n\nthis is our choice !\n\n\n\n\n\n\n\n\nTwo libraries?!\n\n\nSLF4J\n is a \nlogging facade\n API (abstract interface):\nthis is the logging API you will use in your code.\nThis component ensures the interoperability with all your dependencies (that might rely on other logging libraries).\n\n\nLogback\n is the \nbackend implementation\n: this is the underlying library that implements \nthe facade and processes your logs (pushes them to stdout, flat file, with rolling policies, forward them to a \ncentralized system, work asynchronously, ...).\nIt shall never be used directly from your application code. By the way \nSLF4J\n is also able to \nwork with \nLog4J 2\n as the backend implementation (instead of \n\nLogback\n).\n\n\nAll logback \ndocumentation here\n.\n\n\nWhy this choice?\n\n\n\n\nInteroperability\n: \nSLF4J\n has bridges for most other\n  libraries (JUL, commons-logging, Log4J, ...)\n\n\nReliability\n: both projects are still actively developed, tested, documented\n  and supported, with a large user community\n\n\nPerformance\n: \nSLF4J\n + \nLogback\n\n  support a feature called \u00ab parameterized logging \u00bb, that significantly boosts\n  logging performance for disabled logging statement, by not concatenating\n  logging messages (which IS costly)\n\n\nDevOps\n: logback supports externalized configuration, and automatic reload\n  (changing logging levels without restarting your application)\n\n\n... \nand other reasons\n\n\n\n\nBy the way, this choice is now the most popular choice in Java development, and\nis even the default setup when using full-stack web development frameworks such\nas \nDropwizard\n or \nSpring Boot\n.\n\n\nAlso notice that this choice is perfectly compatible with \n\n12 factor apps recommendations\n about logs; effective\nlogs routing will be implemented with logback configuration (apart from application logic).\n\n\nFor more info about the great history of logging libraries in Java, please read:\n\n\n\n\nThe Java Logging Mess\n\n\nBenchmarking Java Logging Frameworks\n\n\nComparison of Java Logging Frameworks and Libraries\n\n\n\n\nNote: your application is using \nLog4J 1\n ?\n\n\n\n\nCheck out this comprehensive article that explains in details \nMigration from log4j\n.\n\n\nNevertheless, you should take the opportunity of this migration to use \ngreat advantages of Logback features\n.\n\n\n\n\n\n\nTop recommendations\n\n\nNever implement your own logging abstraction layer\n\n\nDirectly use the provided logging facade API: \nSLF4J\n.\n\n\nBe aware of the parameters evaluation constraint\n\n\nLogging as follows:\n\n\nlogger.debug(\"Entry number: \" + i + \" is \" + String.valueOf(entry[i]));\n\n\n\n\nincurs the cost of constructing the message parameter, that is converting both\ninteger \ni\n and \nentry[i]\n to a \nString\n, and concatenating intermediate strings.\nThis is regardless of whether the message will be logged or not.\n\n\nSLF4J introduces a better pattern for addressing this issue:\n\n\nObject entry = new SomeObject();\nlogger.debug(\"The entry is {}.\", entry);\n\n\n\n\nOnly after evaluating whether to log or not, and only if the decision is positive,\nwill the logger implementation format the message and replace the \n{}\n pair with\nthe string value of entry.\n\n\nIn other words, this form does not incur the cost of parameter construction when\nthe log statement is disabled.\n\n\nCaution\n: in some cases, even this pattern may cause parameters evaluation.\n\n\nExample:\n\n\nlogger.debug(\"My JSON structure is {}.\", data.toJson());\n\n\n\n\nwill always cause the \ntoJson()\n method to be evaluated...\n\n\nIn such a case, the recommended pattern would be to protect the logging\ninstruction with level checking:\n\n\nif(logger.isDebugEnabled()) {\n  logger.debug(\"My JSON structure is {}.\", data.toJson());\n}\n\n\n\n\nFor more info, please read the \nparameterized logging\n documentation.\n\n\nTake care of the performance cost of log caller context\n\n\nRead carefully the \nConversion Word\n from layouts documentation,\nand avoid directives with the warning \n\"Generating the xxx information is not particularly fast. Thus, its use should be avoided unless execution speed is not an issue.\"\n \n(i.e. \nclass\n, \nfile\n, \n\nline\n, \nmethod\n).\n\n\nThe same recommendation applies to any other kind of logback outputs, for example\navoid the use of \n\"callerData\" LoggingEvents provider\n in the \nlogstash-logback-encoder\n module.\n\n\n\n\nEnrich your logs!\n\n\nWhy\n\n\nQuoting splunk \"\nlogging best practices\n\":\n\n\n\n\nUnique identifiers such as transaction IDs, user IDs, session IDs, request IDs are tremendously helpful when debugging, and even more helpful when you are gathering analytics.\nUnique IDs can point you to the exact transaction, [isolate logs from a single request or logs related to a given user]. Without them, you might only have a time range to use.\nWhen possible, carry these IDs through multiple touch points and avoid changing the format of these IDs between modules. That way, you can track transactions through the system and follow them across machines, networks, and services.\n\n\n\n\nWith SLF4J, the standard way of enriching your logging context with IDs is using\n\nMapped Diagnostic Context\n.\n\n\nTag logs with (unique) request IDs\n\n\nFor instance, wouldn't it be cool to mark every log produced during the processing\nof a request with a (unique) request ID ? Then, with a tool such as Kibana, it would\nbecome so easy to isolate logs from a single request (ElasticSearch query \n\"requestId: 123456789\")...\n\n\nTechnically there are several options to implement this:\n\n\n\n\nWith \nSpring Cloud Sleuth\n,\n\n\nA simpler implementation\n with our \norange-mathoms-logging\n library.\n\n\n\n\nTag logs with user IDs\n\n\nSimilarly, it's also very helpful to mark every log produced during the processing of an \nauthenticated request with the user ID.\n\n\nWith Kibana you will then be able to filter out in one click all logs related to\na single user !\n\n\nWarning\n: for security/privacy reasons, it is highly recommended that the\nuser ID is a technical ID and not a personal information (such as login or email address).\n\n\nYou'll find a \nsimple implementation\n in our \norange-mathoms-logging\n library.\n\n\nMake a signature hash of your errors\n\n\nWhen your system will be in production, you'll have issues. And issues are (generally) \nERROR\n logs with stack traces. But...\n\n\n\n\nHow do you track the error from the client (UI and/or API) to your logs ?\n\n\nHow will you compare stack traces ?\n\n\nCount their frequency ?\n\n\nFind quickly when a problem occurred for the first time ?\n\n\nMake sure a problem has been fixed for good ?\n\n\n...\n\n\n\n\n... the idea we propose is to generate a short, unique ID that identifies your stack trace.\n\n\nThus, the same error occurring twice will have the same ID, allowing you to count, compare, track history of this issue.\n\n\nYou could even join this signature to your client error messages for traceability.\n\n\nImagine the situation...\n\n\n\n\nThe user\n (\nquite upset\n): I just had this \u00ab Internal error [#B23F6545] occurred while calling catalog \u00bb error... your app sucks !\n\nYou\n: no prob\u2019, I simply type-in this \u00ab #B23F6545 \u00bb thing in my Kibana and... bing ! I get the exact stack trace, call flow, occurrences count, ... you\u2019ll have a fix in instants !\n\n\nAudience\n: (applause)\n\n\n\n\n... well, guess what ? You'll also find a \nsimple implementation\n in our \norange-mathoms-logging\n library.\n\n\n\n\nHow to ship logs to Logstash?\n\n\nYou\u2019re using ELK in your project ? Lucky you !\n\n\nWith the \nlogstash-logback-encoder\n\nlibrary, you\u2019ll be able to:\n\n\n\n\nproduce logs in the native logstash JSON format (no file parsing),\n\n\nall your MDC fields are automatically added to the log entry,\n\n\nforward logs directly to a remote logstash server (over UDP or TCP), \n  without needing any shipper (such as\n  \nFilebeat\n, syslog and whatever)\n\n\ntake benefit of a \nLMAX Disruptor RingBuffer\n\n  based appender, with insane performances !!\n\n\n... and lots more\n\n\n\n\n\n\nAbout the authors\n\n\n\n\nDavid Crosson\n\n\nDavid Guyomarch\n\n\nShahnawaz Khan\n\n\nRemy Sanlaville\n\n\nPierre Smeyers",
            "title": "Recommendations"
        },
        {
            "location": "/recommendations/#logging-in-java",
            "text": "This article has been written by Orange Software Expert members\n(see  authors ), and is targeting Java (and JVM-based languages)\ndevelopers, and more specifically server-side developers (JEE or else).  It first gives a clear answer to \"which logging library should I use\", then gives\nseveral technical tips and tools to take the most benefit from your application logs.  Our only goal is to share and spread best practices about logs.",
            "title": "Logging in Java"
        },
        {
            "location": "/recommendations/#which-logging-libraryies",
            "text": "In Java, there are lots of logging libraries:     Library  Comment  Our advise      utils.logging (aka JUL)  Functionally and technically, it lags behind competitors  do not use it    Log4J 1  Too old, not maintained anymore  do not use it    Apache commons-logging  Too old, not maintained anymore  do not use it    Log4J 2  Seems okay, but clearly not very popular  no concrete feedback for now    SLF4J  +  logback  See reasons below  this is our choice !",
            "title": "Which logging library(ies)?"
        },
        {
            "location": "/recommendations/#two-libraries",
            "text": "SLF4J  is a  logging facade  API (abstract interface):\nthis is the logging API you will use in your code.\nThis component ensures the interoperability with all your dependencies (that might rely on other logging libraries).  Logback  is the  backend implementation : this is the underlying library that implements \nthe facade and processes your logs (pushes them to stdout, flat file, with rolling policies, forward them to a \ncentralized system, work asynchronously, ...).\nIt shall never be used directly from your application code. By the way  SLF4J  is also able to \nwork with  Log4J 2  as the backend implementation (instead of  Logback ).  All logback  documentation here .",
            "title": "Two libraries?!"
        },
        {
            "location": "/recommendations/#why-this-choice",
            "text": "Interoperability :  SLF4J  has bridges for most other\n  libraries (JUL, commons-logging, Log4J, ...)  Reliability : both projects are still actively developed, tested, documented\n  and supported, with a large user community  Performance :  SLF4J  +  Logback \n  support a feature called \u00ab parameterized logging \u00bb, that significantly boosts\n  logging performance for disabled logging statement, by not concatenating\n  logging messages (which IS costly)  DevOps : logback supports externalized configuration, and automatic reload\n  (changing logging levels without restarting your application)  ...  and other reasons   By the way, this choice is now the most popular choice in Java development, and\nis even the default setup when using full-stack web development frameworks such\nas  Dropwizard  or  Spring Boot .  Also notice that this choice is perfectly compatible with  12 factor apps recommendations  about logs; effective\nlogs routing will be implemented with logback configuration (apart from application logic).  For more info about the great history of logging libraries in Java, please read:   The Java Logging Mess  Benchmarking Java Logging Frameworks  Comparison of Java Logging Frameworks and Libraries   Note: your application is using  Log4J 1  ?   Check out this comprehensive article that explains in details  Migration from log4j .  Nevertheless, you should take the opportunity of this migration to use  great advantages of Logback features .",
            "title": "Why this choice?"
        },
        {
            "location": "/recommendations/#top-recommendations",
            "text": "",
            "title": "Top recommendations"
        },
        {
            "location": "/recommendations/#never-implement-your-own-logging-abstraction-layer",
            "text": "Directly use the provided logging facade API:  SLF4J .",
            "title": "Never implement your own logging abstraction layer"
        },
        {
            "location": "/recommendations/#be-aware-of-the-parameters-evaluation-constraint",
            "text": "Logging as follows:  logger.debug(\"Entry number: \" + i + \" is \" + String.valueOf(entry[i]));  incurs the cost of constructing the message parameter, that is converting both\ninteger  i  and  entry[i]  to a  String , and concatenating intermediate strings.\nThis is regardless of whether the message will be logged or not.  SLF4J introduces a better pattern for addressing this issue:  Object entry = new SomeObject();\nlogger.debug(\"The entry is {}.\", entry);  Only after evaluating whether to log or not, and only if the decision is positive,\nwill the logger implementation format the message and replace the  {}  pair with\nthe string value of entry.  In other words, this form does not incur the cost of parameter construction when\nthe log statement is disabled.  Caution : in some cases, even this pattern may cause parameters evaluation.  Example:  logger.debug(\"My JSON structure is {}.\", data.toJson());  will always cause the  toJson()  method to be evaluated...  In such a case, the recommended pattern would be to protect the logging\ninstruction with level checking:  if(logger.isDebugEnabled()) {\n  logger.debug(\"My JSON structure is {}.\", data.toJson());\n}  For more info, please read the  parameterized logging  documentation.",
            "title": "Be aware of the parameters evaluation constraint"
        },
        {
            "location": "/recommendations/#take-care-of-the-performance-cost-of-log-caller-context",
            "text": "Read carefully the  Conversion Word  from layouts documentation,\nand avoid directives with the warning  \"Generating the xxx information is not particularly fast. Thus, its use should be avoided unless execution speed is not an issue.\"  \n(i.e.  class ,  file ,  line ,  method ).  The same recommendation applies to any other kind of logback outputs, for example\navoid the use of  \"callerData\" LoggingEvents provider  in the  logstash-logback-encoder  module.",
            "title": "Take care of the performance cost of log caller context"
        },
        {
            "location": "/recommendations/#enrich-your-logs",
            "text": "",
            "title": "Enrich your logs!"
        },
        {
            "location": "/recommendations/#why",
            "text": "Quoting splunk \" logging best practices \":   Unique identifiers such as transaction IDs, user IDs, session IDs, request IDs are tremendously helpful when debugging, and even more helpful when you are gathering analytics.\nUnique IDs can point you to the exact transaction, [isolate logs from a single request or logs related to a given user]. Without them, you might only have a time range to use.\nWhen possible, carry these IDs through multiple touch points and avoid changing the format of these IDs between modules. That way, you can track transactions through the system and follow them across machines, networks, and services.   With SLF4J, the standard way of enriching your logging context with IDs is using Mapped Diagnostic Context .",
            "title": "Why"
        },
        {
            "location": "/recommendations/#tag-logs-with-unique-request-ids",
            "text": "For instance, wouldn't it be cool to mark every log produced during the processing\nof a request with a (unique) request ID ? Then, with a tool such as Kibana, it would\nbecome so easy to isolate logs from a single request (ElasticSearch query \n\"requestId: 123456789\")...  Technically there are several options to implement this:   With  Spring Cloud Sleuth ,  A simpler implementation  with our  orange-mathoms-logging  library.",
            "title": "Tag logs with (unique) request IDs"
        },
        {
            "location": "/recommendations/#tag-logs-with-user-ids",
            "text": "Similarly, it's also very helpful to mark every log produced during the processing of an \nauthenticated request with the user ID.  With Kibana you will then be able to filter out in one click all logs related to\na single user !  Warning : for security/privacy reasons, it is highly recommended that the\nuser ID is a technical ID and not a personal information (such as login or email address).  You'll find a  simple implementation  in our  orange-mathoms-logging  library.",
            "title": "Tag logs with user IDs"
        },
        {
            "location": "/recommendations/#make-a-signature-hash-of-your-errors",
            "text": "When your system will be in production, you'll have issues. And issues are (generally)  ERROR  logs with stack traces. But...   How do you track the error from the client (UI and/or API) to your logs ?  How will you compare stack traces ?  Count their frequency ?  Find quickly when a problem occurred for the first time ?  Make sure a problem has been fixed for good ?  ...   ... the idea we propose is to generate a short, unique ID that identifies your stack trace.  Thus, the same error occurring twice will have the same ID, allowing you to count, compare, track history of this issue.  You could even join this signature to your client error messages for traceability.  Imagine the situation...   The user  ( quite upset ): I just had this \u00ab Internal error [#B23F6545] occurred while calling catalog \u00bb error... your app sucks ! You : no prob\u2019, I simply type-in this \u00ab #B23F6545 \u00bb thing in my Kibana and... bing ! I get the exact stack trace, call flow, occurrences count, ... you\u2019ll have a fix in instants !  Audience : (applause)   ... well, guess what ? You'll also find a  simple implementation  in our  orange-mathoms-logging  library.",
            "title": "Make a signature hash of your errors"
        },
        {
            "location": "/recommendations/#how-to-ship-logs-to-logstash",
            "text": "You\u2019re using ELK in your project ? Lucky you !  With the  logstash-logback-encoder \nlibrary, you\u2019ll be able to:   produce logs in the native logstash JSON format (no file parsing),  all your MDC fields are automatically added to the log entry,  forward logs directly to a remote logstash server (over UDP or TCP), \n  without needing any shipper (such as\n   Filebeat , syslog and whatever)  take benefit of a  LMAX Disruptor RingBuffer \n  based appender, with insane performances !!  ... and lots more",
            "title": "How to ship logs to Logstash?"
        },
        {
            "location": "/recommendations/#about-the-authors",
            "text": "David Crosson  David Guyomarch  Shahnawaz Khan  Remy Sanlaville  Pierre Smeyers",
            "title": "About the authors"
        },
        {
            "location": "/logging-code/",
            "text": "A deeper look into the code\n\n\nThis chapter details all specific stuff coded or configured in Woofer related to logging.\n\n\n\n\nFeatured logging tools\n\n\nWoofer uses the following libraries:\n\n\n\n\nSLF4J\n and \nLogback\n as the logging facade and implementation (the default with Spring Boot).\n\n\nlogstash-logback-encoder\n, a great Logback add-on that enables \nshipping logs directly to Logstash in JSON format over TCP or UDP.\n\n\nSpring Cloud Sleuth\n for distributed tracing & logs correlation.\n\n\nour \norange-mathoms-logging\n library that brings additional useful stuff.\n\n\n\n\n\n\nDistributed tracing & logs correlation\n\n\nEspecially in a microservices architecture, a request may go through several tiers (apache, j2ee server, bdd...) and it's not a trivial task to\nunderstand and follow the callflow and spot the root cause of an error.\n\n\nThat's why it is so important to have a way of correlating logs produced from different tiers, but related to the same \ntreatment\n.\n\n\nThis is demonstrated in our \nIncident Analysis\n section.\n\n\nDistributed tracing feature in Woofer is brought by \nSpring Cloud Sleuth\n.\n\n\nIt only requires to be installed (follow quick start), and - \nhere we go\n:\n\n\n\n\nlogs are automatically enriched with tracing context:\n\n\nX-B3-TraceId\n: unique ID for an overall \ntreatment\n (across several services),\n\n\nX-B3-SpanId\n: unique ID for a basic unit of work (one thread on one server),\n\n\nX-Span-Export\n: whether or not the span is exported in the current span.\n\n\n\n\n\n\ntracing context is automatically propagated upon calling other services (through standard HTTP headers).\n\n\n\n\n\n\nEnrich logs with user IDs\n\n\nLogs from the \nwoofer-webfront\n component are enriched with a \nuserId\n field, that is the user's login.\n\n\nThis is done using the \nPrincipalFilter\n from the \norange-mathoms-logging\n library (\nsee doc\n).\n\n\n\n\nEnrich logs with session IDs\n\n\nLogs from the \nwoofer-webfront\n component are enriched with a \nsessionId\n field, that is the current user's session ID.\n\n\nThis is done using the \nSessionIdFilter\n from the \norange-mathoms-logging\n library (\nsee doc\n).\n\n\n\n\nEnrich stack traces with unique signatures\n\n\nThe idea is to generate a short, unique ID that identifies your stack trace.\n\n\nIt is an easy way to track the error from the client (UI and/or API) to your logs, count their frequency, make sure a problem has been fixed for good...\n\n\nThis is done using the \nShortenedThrowableConverter\n & \nStackHashJsonProvider\n components from the \nlogstash-logback-encoder\n library (available from version \n4.11\n) (\nsee doc\n).\n\n\n\n\nError management\n\n\nError management in a web application is undoubtedly a complex task. It covers several topics:\n\n\n\n    \nerror to http mapping\n\n    \n\n        How each Java error should be mapped to HTTP error? Which status code? Which (human readable) message?\n        Generally speaking, you'll have to deal both with your own Java exceptions, and also errors from the underlying framework (Spring or else).\n    \n\n    \n\n    \ncontent negotiation\n\n    \n\n        When an error occurs, depending on the requesting client, you may have to render a human readable web page, \n        a JSON response, an XML response or else.\n    \n\n    \n\n    \nintegrate to your framework\n\n    \n\n        The way you will implement this logic will heavily depend on the framework you're using.\n    \n\n\n\n\n\nError handlers in Woofer\n\n\nThe \nerror handler\n is a technical component linked to the underlying framework in charge of handling Java exceptions (intercept, turn it into a HTTP error, and display it to the client in an appropriate way).\n\n\nIn Woofer, error handling is implemented by:\n\n\n\n\nAbstractGlobalErrorHandler\n: an abstract error handler that:\n\n\nglobally intercepts any unhandled \nSpring MVC Exceptions\n,\n\n\nexposes a global exception rendering endpoint,\n\n\nthat can be registered at the JEE container level and therefore is able to render non-Spring MVC errors (Spring Security or else),\n\n\nmaps any exception (Spring MVC or else) to:\n\n\nan HTTP status,\n\n\nan error code (based on \ncommon Orange Partner error codes\n),\n\n\na human-understandable error description.\n\n\n\n\n\n\n\n\n\n\nRestErrorHandler\n: implementation that renders errors into JSON,\n\n\nRestAndHtmlErrorHandler\n: an implementation that supports both JSON and html rendering (using content negotiation).\n\n\n\n\nBoth behave quite differently if the error is a \nclient\n error or an \ninternal\n (server) error.\n\n\nA client error (HTTP \n4XX\n) is supposed to be due to a wrong usage of the API or application by the user. The error handler \nsimply displays some hints about the error (if you have started woofer locally, you may try this by navigating on this \n\nlink with missing parameter\n of \n\npath that does not exist\n).\n\n\nA server error (HTTP \n5XX\n) - on the contrary - is due to an internal issue (a bloody \nNullPointerException\n or any technical stuff going wrong in your code), and as such needs a specific treatment:\n\n\n\n\nnever display a cryptic error message or ugly stack strace\n to the end user, but instead display a generic \n\"so sorry, we're working on it\"\n error message ;-)\n\n\nlog the original Java error with full details to allow further analysis and maybe raise an alarm in production,\n\n\nbe able to have error traceability (see below).\n\n\n\n\nThat's what \nAbstractGlobalErrorHandler\n does in case of internal errors:\n\n\n\n\ngenerates a unique error ID,\n\n\nadds this ID to the response headers (\nX-Error-Uid\n),\n\n\ndisplays a generic error message, that includes this unique ID (ex: \nInternal error [#d7506d00-99f2c6eb90682] occurred in request 'GET /misc/err/500'\n),\n\n\nlogs the original Java error, with the unique error ID.\n\n\n\n\nThe unique error ID (displayed to the user) can then be used to retrieve the complete original stack trace, and start incident analysis: that's error traceability.\n\n\nNOTE: Spring supports \nlots of ways of managing exceptions\n \n(probably too many). I chose to implement it with:\n\n\n\n\n@ControllerAdvice\n + \n@ExceptionHandler\n: to globally intercept any unhandled Spring MVC exception,\n\n\nErrorController\n: declares the component as the controller in charge of rendering any error at the JEE container level.\n\n\n\n\nThis is the design that suits the best my needs (render ALL errors, including non-Spring MVC, and manage content negotiation).\n\n\n\n\nShipping logs directly to Logstash\n\n\nUsing the \nlogstash\n \nprofile\n,\nlogback is configured to ship directly application and access logs to \nLogstash\n over TCP,\nusing the amazing \nlogstash-logback-encoder\n library.\n\n\nConfiguration for Java logs\n\n\nLogback configuration for Java logs also uses \nShortenedThrowableConverter\n & \nStackHashJsonProvider\n components\n(\nsee doc\n)\nto enrich stack traces with unique signatures.\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- application logging configuration to ship logs directly to Logstash -->\n<configuration>\n  <!-- define exclusion patterns as a property -->\n  <property name=\"STE_EXCLUSIONS\" value=\"\\$\\$FastClassByCGLIB\\$\\$,\\$\\$EnhancerBySpringCGLIB\\$\\$,^sun\\.reflect\\..*\\.invoke,^com\\.sun\\.,^sun\\.net\\.,^net\\.sf\\.cglib\\.proxy\\.MethodProxy\\.invoke,^org\\.springframework\\.cglib\\.,^org\\.springframework\\.transaction\\.,^org\\.springframework\\.validation\\.,^org\\.springframework\\.app\\.,^org\\.springframework\\.aop\\.,^java\\.lang\\.reflect\\.Method\\.invoke,^org\\.springframework\\.ws\\..*\\.invoke,^org\\.springframework\\.ws\\.transport\\.,^org\\.springframework\\.ws\\.soap\\.saaj\\.SaajSoapMessage\\.,^org\\.springframework\\.ws\\.client\\.core\\.WebServiceTemplate\\.,^org\\.springframework\\.web\\.filter\\.,^org\\.springframework\\.boot\\.web\\.filter\\.,^org\\.springframework\\.util\\.ReflectionUtils\\.invokeMethod$,^org\\.apache\\.tomcat\\.,^org\\.apache\\.catalina\\.,^org\\.apache\\.coyote\\.,^java\\.util\\.concurrent\\.ThreadPoolExecutor\\.runWorker,^java\\.lang\\.Thread\\.run$,^rx\\.\"/>\n\n  <appender name=\"TCP\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\">\n    <!-- remote Logstash server -->\n    <remoteHost>${LOGSTASH_HOST}</remoteHost>\n    <port>${LOGSTASH_PORT}</port>\n    <encoder class=\"net.logstash.logback.encoder.LogstashEncoder\">\n      <!-- computes and adds a 'stack_hash' field on errors -->\n      <provider class=\"net.logstash.logback.composite.loggingevent.StackHashJsonProvider\">\n        <exclusions>${STE_EXCLUSIONS}</exclusions>\n      </provider>\n      <!-- enriches the stack trace with unique hash -->\n      <throwableConverter class=\"net.logstash.logback.stacktrace.ShortenedThrowableConverter\">\n        <inlineHash>true</inlineHash>\n        <exclusions>${STE_EXCLUSIONS}</exclusions>\n      </throwableConverter>\n      <customFields>{\"@project\":\"${MD_PROJECT:--}\",\"@app\":\"webfront\",\"@type\":\"java\"}</customFields>\n    </encoder>\n  </appender>\n\n  <logger name=\"com.orange\" level=\"DEBUG\" />\n\n  <root level=\"INFO\">\n    <appender-ref ref=\"TCP\" />\n  </root>\n</configuration>\n\n\n\n\nNOTE: The \nLogstash\n server address is configured with non-standard Spring configuration \ncustom.logging.collector.host\n and \ncustom.logging.collector.port\n.\n\n\nWith this configuration, a single Java log in Elasticsearch will look like this:\n\n\n{\n  \"@version\": 1,\n  \"@timestamp\": \"2017-03-17T14:21:25.643Z\",\n  \"host\": \"10.100.0.216\",\n  \"port\": 46070,\n  \"HOSTNAME\": \"oswewooffront\",\n  \"@app\": \"woofer-webfront\",\n  \"@type\": \"java\",\n  \"logger_name\": \"com.orange.oswe.demo.woofer.commons.error.RestErrorController\",\n  \"level\": \"ERROR\",\n  \"level_value\": 40000,\n  \"message\": \"Internal error [#fe8ad9ce-317d85359a8531] occurred in request 'POST /woofs'\",\n  \"thread_name\": \"http-nio-8080-exec-6\",\n  \"stack_trace\": \"#fe8ad9ce> com.netflix.hystrix.exception.HystrixRuntimeException: ...\",\n  \"stack_hash\": \"fe8ad9ce\",\n  \"userId\": \"bpitt\",\n  \"sessionId\": \"B3FD051F22C031B5A813B29D32EFF383\",\n  \"X-B3-TraceId\": \"8210b57467b85195\",\n  \"X-B3-SpanId\": \"8210b57467b85195\",\n  \"X-Span-Export\": \"false\"\n}\n\n\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n@version\n\n\nstandard Elasticsearch field set by Logstash\n\n\n\n\n\n\n@timestamp\n\n\nstandard Elasticsearch field set by Logback\n\n\n\n\n\n\nhost\n\n\nset by Logstash\n\n\n\n\n\n\nport\n\n\nset by Logstash\n\n\n\n\n\n\nHOSTNAME\n\n\nset by Logback\n\n\n\n\n\n\n@app\n\n\ncustom field set by configuration (the name of the origin microservice)\n\n\n\n\n\n\n@type\n\n\ncustom field set by configuration (type of the log)\n\n\n\n\n\n\nlogger_name\n\n\nset by Logback\n\n\n\n\n\n\nlevel\n\n\nset by Logback\n\n\n\n\n\n\nlevel_value\n\n\nset by Logback\n\n\n\n\n\n\nmessage\n\n\nset by Logback\n\n\n\n\n\n\nthread_name\n\n\nset by Logback\n\n\n\n\n\n\nstack_trace\n\n\nset by Logback, content valuated by the \nShortenedThrowableConverter\n component\n\n\n\n\n\n\nstack_hash\n\n\ncustom field set by the \nStackHashJsonProvider\n component\n\n\n\n\n\n\nuserId\n\n\ncustom MDC field set by the \nPrincipalFilter\n component\n\n\n\n\n\n\nsessionId\n\n\ncustom MDC field set by the \nSessionIdFilter\n component\n\n\n\n\n\n\nX-B3-TraceId\n\n\nMDC field set by Spring Cloud Sleuth for logs correlation\n\n\n\n\n\n\nX-B3-SpanId\n\n\nMDC field set by Spring Cloud Sleuth for logs correlation\n\n\n\n\n\n\nX-Span-Export\n\n\nMDC field set by Spring Cloud Sleuth for logs correlation\n\n\n\n\n\n\n\n\nConfiguration for access logs (embedded tomcat)\n\n\nGenerally speaking, Logback integration to Spring Boot is quite seamless with respect to Java logs, but it is\nfar from the case with embedded Tomcat access logs. Spring Boot will probably improve on this aspect in the future.\n\n\nIn Woofer, access logs are configured by the\n\nTomcatCustomizerForLogback\n\nclass by adding the \nLogbackValve\n to Tomcat's context.\n\n\nHere is the logback xml configuration for access log using the \nlogstash\n\n\nprofile\n:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- access log configuration to ship logs directly to Logstash -->\n<configuration>\n  <statusListener class=\"ch.qos.logback.core.status.OnConsoleStatusListener\" />\n\n  <!-- TCP -->\n  <appender name=\"TCP\" class=\"net.logstash.logback.appender.LogstashAccessTcpSocketAppender\">\n    <!-- remote Logstash server -->\n    <remoteHost>${LOGSTASH_HOST}</remoteHost>\n    <port>${LOGSTASH_PORT}</port>\n    <encoder class=\"net.logstash.logback.encoder.AccessEventCompositeJsonEncoder\">\n      <providers>\n        <timestamp/>\n        <version/>\n        <pattern>\n          <pattern>\n            {\n              \"@project\":\"${MD_PROJECT:--}\",\n              \"@app\":\"webfront\",\n              \"@type\":\"http\",\n              \"X-B3-TraceId\":\"%header{X-B3-TraceId}\",\n              \"req\": {\n                \"host\": \"%clientHost\",\n                \"url\": \"%requestURL\",\n                \"meth\": \"%requestMethod\",\n                \"uri\": \"%requestURI\"\n              },\n              \"resp\": {\n                \"status\": \"#asLong{%statusCode}\",\n                \"size\": \"#asLong{%bytesSent}\"\n              },\n              \"elapsed\": \"#asLong{%elapsedTime}\"\n              }\n          </pattern>\n        </pattern>\n      </providers>\n    </encoder>\n  </appender>\n\n  <appender-ref ref=\"TCP\" />\n</configuration>\n\n\n\n\nNOTE: You can see that this configuration allows us to control exactly the JSON structure of an access log sent to \nElasticsearch\n via \nLogstash\n.\n\n\nNotice that the access logs also use the same custom fields as Java logs (\n@app\n, \n@type\n, \n@project\n, with \n@type\n equals to \nhttp\n).\n\n\nFor more info about Logback & access logs, have a look at:\n\n\n\n\nLogback access\n\n\nLogback \nPatternLayout\n\n\nlogstash-logback-encoder \nAccessEvent patterns\n\n\n\n\nLogstash configuration\n\n\nIn order to be able to send directly logs in JSON format to Logstash, you will simply have to setup a Logstash \ntcp\n\ninput with \njson\n codec as follows:\n\n\ninput {\n  tcp {\n    port => 4321\n    codec => json\n  }\n}",
            "title": "Code"
        },
        {
            "location": "/logging-code/#a-deeper-look-into-the-code",
            "text": "This chapter details all specific stuff coded or configured in Woofer related to logging.",
            "title": "A deeper look into the code"
        },
        {
            "location": "/logging-code/#featured-logging-tools",
            "text": "Woofer uses the following libraries:   SLF4J  and  Logback  as the logging facade and implementation (the default with Spring Boot).  logstash-logback-encoder , a great Logback add-on that enables \nshipping logs directly to Logstash in JSON format over TCP or UDP.  Spring Cloud Sleuth  for distributed tracing & logs correlation.  our  orange-mathoms-logging  library that brings additional useful stuff.",
            "title": "Featured logging tools"
        },
        {
            "location": "/logging-code/#distributed-tracing-logs-correlation",
            "text": "Especially in a microservices architecture, a request may go through several tiers (apache, j2ee server, bdd...) and it's not a trivial task to\nunderstand and follow the callflow and spot the root cause of an error.  That's why it is so important to have a way of correlating logs produced from different tiers, but related to the same  treatment .  This is demonstrated in our  Incident Analysis  section.  Distributed tracing feature in Woofer is brought by  Spring Cloud Sleuth .  It only requires to be installed (follow quick start), and -  here we go :   logs are automatically enriched with tracing context:  X-B3-TraceId : unique ID for an overall  treatment  (across several services),  X-B3-SpanId : unique ID for a basic unit of work (one thread on one server),  X-Span-Export : whether or not the span is exported in the current span.    tracing context is automatically propagated upon calling other services (through standard HTTP headers).",
            "title": "Distributed tracing &amp; logs correlation"
        },
        {
            "location": "/logging-code/#enrich-logs-with-user-ids",
            "text": "Logs from the  woofer-webfront  component are enriched with a  userId  field, that is the user's login.  This is done using the  PrincipalFilter  from the  orange-mathoms-logging  library ( see doc ).",
            "title": "Enrich logs with user IDs"
        },
        {
            "location": "/logging-code/#enrich-logs-with-session-ids",
            "text": "Logs from the  woofer-webfront  component are enriched with a  sessionId  field, that is the current user's session ID.  This is done using the  SessionIdFilter  from the  orange-mathoms-logging  library ( see doc ).",
            "title": "Enrich logs with session IDs"
        },
        {
            "location": "/logging-code/#enrich-stack-traces-with-unique-signatures",
            "text": "The idea is to generate a short, unique ID that identifies your stack trace.  It is an easy way to track the error from the client (UI and/or API) to your logs, count their frequency, make sure a problem has been fixed for good...  This is done using the  ShortenedThrowableConverter  &  StackHashJsonProvider  components from the  logstash-logback-encoder  library (available from version  4.11 ) ( see doc ).",
            "title": "Enrich stack traces with unique signatures"
        },
        {
            "location": "/logging-code/#error-management",
            "text": "Error management in a web application is undoubtedly a complex task. It covers several topics:  \n     error to http mapping \n     \n        How each Java error should be mapped to HTTP error? Which status code? Which (human readable) message?\n        Generally speaking, you'll have to deal both with your own Java exceptions, and also errors from the underlying framework (Spring or else).\n     \n     \n     content negotiation \n     \n        When an error occurs, depending on the requesting client, you may have to render a human readable web page, \n        a JSON response, an XML response or else.\n     \n     \n     integrate to your framework \n     \n        The way you will implement this logic will heavily depend on the framework you're using.",
            "title": "Error management"
        },
        {
            "location": "/logging-code/#error-handlers-in-woofer",
            "text": "The  error handler  is a technical component linked to the underlying framework in charge of handling Java exceptions (intercept, turn it into a HTTP error, and display it to the client in an appropriate way).  In Woofer, error handling is implemented by:   AbstractGlobalErrorHandler : an abstract error handler that:  globally intercepts any unhandled  Spring MVC Exceptions ,  exposes a global exception rendering endpoint,  that can be registered at the JEE container level and therefore is able to render non-Spring MVC errors (Spring Security or else),  maps any exception (Spring MVC or else) to:  an HTTP status,  an error code (based on  common Orange Partner error codes ),  a human-understandable error description.      RestErrorHandler : implementation that renders errors into JSON,  RestAndHtmlErrorHandler : an implementation that supports both JSON and html rendering (using content negotiation).   Both behave quite differently if the error is a  client  error or an  internal  (server) error.  A client error (HTTP  4XX ) is supposed to be due to a wrong usage of the API or application by the user. The error handler \nsimply displays some hints about the error (if you have started woofer locally, you may try this by navigating on this  link with missing parameter  of  path that does not exist ).  A server error (HTTP  5XX ) - on the contrary - is due to an internal issue (a bloody  NullPointerException  or any technical stuff going wrong in your code), and as such needs a specific treatment:   never display a cryptic error message or ugly stack strace  to the end user, but instead display a generic  \"so sorry, we're working on it\"  error message ;-)  log the original Java error with full details to allow further analysis and maybe raise an alarm in production,  be able to have error traceability (see below).   That's what  AbstractGlobalErrorHandler  does in case of internal errors:   generates a unique error ID,  adds this ID to the response headers ( X-Error-Uid ),  displays a generic error message, that includes this unique ID (ex:  Internal error [#d7506d00-99f2c6eb90682] occurred in request 'GET /misc/err/500' ),  logs the original Java error, with the unique error ID.   The unique error ID (displayed to the user) can then be used to retrieve the complete original stack trace, and start incident analysis: that's error traceability.  NOTE: Spring supports  lots of ways of managing exceptions  \n(probably too many). I chose to implement it with:   @ControllerAdvice  +  @ExceptionHandler : to globally intercept any unhandled Spring MVC exception,  ErrorController : declares the component as the controller in charge of rendering any error at the JEE container level.   This is the design that suits the best my needs (render ALL errors, including non-Spring MVC, and manage content negotiation).",
            "title": "Error handlers in Woofer"
        },
        {
            "location": "/logging-code/#shipping-logs-directly-to-logstash",
            "text": "Using the  logstash   profile ,\nlogback is configured to ship directly application and access logs to  Logstash  over TCP,\nusing the amazing  logstash-logback-encoder  library.",
            "title": "Shipping logs directly to Logstash"
        },
        {
            "location": "/logging-code/#configuration-for-java-logs",
            "text": "Logback configuration for Java logs also uses  ShortenedThrowableConverter  &  StackHashJsonProvider  components\n( see doc )\nto enrich stack traces with unique signatures.  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- application logging configuration to ship logs directly to Logstash -->\n<configuration>\n  <!-- define exclusion patterns as a property -->\n  <property name=\"STE_EXCLUSIONS\" value=\"\\$\\$FastClassByCGLIB\\$\\$,\\$\\$EnhancerBySpringCGLIB\\$\\$,^sun\\.reflect\\..*\\.invoke,^com\\.sun\\.,^sun\\.net\\.,^net\\.sf\\.cglib\\.proxy\\.MethodProxy\\.invoke,^org\\.springframework\\.cglib\\.,^org\\.springframework\\.transaction\\.,^org\\.springframework\\.validation\\.,^org\\.springframework\\.app\\.,^org\\.springframework\\.aop\\.,^java\\.lang\\.reflect\\.Method\\.invoke,^org\\.springframework\\.ws\\..*\\.invoke,^org\\.springframework\\.ws\\.transport\\.,^org\\.springframework\\.ws\\.soap\\.saaj\\.SaajSoapMessage\\.,^org\\.springframework\\.ws\\.client\\.core\\.WebServiceTemplate\\.,^org\\.springframework\\.web\\.filter\\.,^org\\.springframework\\.boot\\.web\\.filter\\.,^org\\.springframework\\.util\\.ReflectionUtils\\.invokeMethod$,^org\\.apache\\.tomcat\\.,^org\\.apache\\.catalina\\.,^org\\.apache\\.coyote\\.,^java\\.util\\.concurrent\\.ThreadPoolExecutor\\.runWorker,^java\\.lang\\.Thread\\.run$,^rx\\.\"/>\n\n  <appender name=\"TCP\" class=\"net.logstash.logback.appender.LogstashTcpSocketAppender\">\n    <!-- remote Logstash server -->\n    <remoteHost>${LOGSTASH_HOST}</remoteHost>\n    <port>${LOGSTASH_PORT}</port>\n    <encoder class=\"net.logstash.logback.encoder.LogstashEncoder\">\n      <!-- computes and adds a 'stack_hash' field on errors -->\n      <provider class=\"net.logstash.logback.composite.loggingevent.StackHashJsonProvider\">\n        <exclusions>${STE_EXCLUSIONS}</exclusions>\n      </provider>\n      <!-- enriches the stack trace with unique hash -->\n      <throwableConverter class=\"net.logstash.logback.stacktrace.ShortenedThrowableConverter\">\n        <inlineHash>true</inlineHash>\n        <exclusions>${STE_EXCLUSIONS}</exclusions>\n      </throwableConverter>\n      <customFields>{\"@project\":\"${MD_PROJECT:--}\",\"@app\":\"webfront\",\"@type\":\"java\"}</customFields>\n    </encoder>\n  </appender>\n\n  <logger name=\"com.orange\" level=\"DEBUG\" />\n\n  <root level=\"INFO\">\n    <appender-ref ref=\"TCP\" />\n  </root>\n</configuration>  NOTE: The  Logstash  server address is configured with non-standard Spring configuration  custom.logging.collector.host  and  custom.logging.collector.port .  With this configuration, a single Java log in Elasticsearch will look like this:  {\n  \"@version\": 1,\n  \"@timestamp\": \"2017-03-17T14:21:25.643Z\",\n  \"host\": \"10.100.0.216\",\n  \"port\": 46070,\n  \"HOSTNAME\": \"oswewooffront\",\n  \"@app\": \"woofer-webfront\",\n  \"@type\": \"java\",\n  \"logger_name\": \"com.orange.oswe.demo.woofer.commons.error.RestErrorController\",\n  \"level\": \"ERROR\",\n  \"level_value\": 40000,\n  \"message\": \"Internal error [#fe8ad9ce-317d85359a8531] occurred in request 'POST /woofs'\",\n  \"thread_name\": \"http-nio-8080-exec-6\",\n  \"stack_trace\": \"#fe8ad9ce> com.netflix.hystrix.exception.HystrixRuntimeException: ...\",\n  \"stack_hash\": \"fe8ad9ce\",\n  \"userId\": \"bpitt\",\n  \"sessionId\": \"B3FD051F22C031B5A813B29D32EFF383\",\n  \"X-B3-TraceId\": \"8210b57467b85195\",\n  \"X-B3-SpanId\": \"8210b57467b85195\",\n  \"X-Span-Export\": \"false\"\n}     Field  Description      @version  standard Elasticsearch field set by Logstash    @timestamp  standard Elasticsearch field set by Logback    host  set by Logstash    port  set by Logstash    HOSTNAME  set by Logback    @app  custom field set by configuration (the name of the origin microservice)    @type  custom field set by configuration (type of the log)    logger_name  set by Logback    level  set by Logback    level_value  set by Logback    message  set by Logback    thread_name  set by Logback    stack_trace  set by Logback, content valuated by the  ShortenedThrowableConverter  component    stack_hash  custom field set by the  StackHashJsonProvider  component    userId  custom MDC field set by the  PrincipalFilter  component    sessionId  custom MDC field set by the  SessionIdFilter  component    X-B3-TraceId  MDC field set by Spring Cloud Sleuth for logs correlation    X-B3-SpanId  MDC field set by Spring Cloud Sleuth for logs correlation    X-Span-Export  MDC field set by Spring Cloud Sleuth for logs correlation",
            "title": "Configuration for Java logs"
        },
        {
            "location": "/logging-code/#configuration-for-access-logs-embedded-tomcat",
            "text": "Generally speaking, Logback integration to Spring Boot is quite seamless with respect to Java logs, but it is\nfar from the case with embedded Tomcat access logs. Spring Boot will probably improve on this aspect in the future.  In Woofer, access logs are configured by the TomcatCustomizerForLogback \nclass by adding the  LogbackValve  to Tomcat's context.  Here is the logback xml configuration for access log using the  logstash  profile :  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- access log configuration to ship logs directly to Logstash -->\n<configuration>\n  <statusListener class=\"ch.qos.logback.core.status.OnConsoleStatusListener\" />\n\n  <!-- TCP -->\n  <appender name=\"TCP\" class=\"net.logstash.logback.appender.LogstashAccessTcpSocketAppender\">\n    <!-- remote Logstash server -->\n    <remoteHost>${LOGSTASH_HOST}</remoteHost>\n    <port>${LOGSTASH_PORT}</port>\n    <encoder class=\"net.logstash.logback.encoder.AccessEventCompositeJsonEncoder\">\n      <providers>\n        <timestamp/>\n        <version/>\n        <pattern>\n          <pattern>\n            {\n              \"@project\":\"${MD_PROJECT:--}\",\n              \"@app\":\"webfront\",\n              \"@type\":\"http\",\n              \"X-B3-TraceId\":\"%header{X-B3-TraceId}\",\n              \"req\": {\n                \"host\": \"%clientHost\",\n                \"url\": \"%requestURL\",\n                \"meth\": \"%requestMethod\",\n                \"uri\": \"%requestURI\"\n              },\n              \"resp\": {\n                \"status\": \"#asLong{%statusCode}\",\n                \"size\": \"#asLong{%bytesSent}\"\n              },\n              \"elapsed\": \"#asLong{%elapsedTime}\"\n              }\n          </pattern>\n        </pattern>\n      </providers>\n    </encoder>\n  </appender>\n\n  <appender-ref ref=\"TCP\" />\n</configuration>  NOTE: You can see that this configuration allows us to control exactly the JSON structure of an access log sent to  Elasticsearch  via  Logstash .  Notice that the access logs also use the same custom fields as Java logs ( @app ,  @type ,  @project , with  @type  equals to  http ).  For more info about Logback & access logs, have a look at:   Logback access  Logback  PatternLayout  logstash-logback-encoder  AccessEvent patterns",
            "title": "Configuration for access logs (embedded tomcat)"
        },
        {
            "location": "/logging-code/#logstash-configuration",
            "text": "In order to be able to send directly logs in JSON format to Logstash, you will simply have to setup a Logstash  tcp \ninput with  json  codec as follows:  input {\n  tcp {\n    port => 4321\n    codec => json\n  }\n}",
            "title": "Logstash configuration"
        },
        {
            "location": "/introduction/",
            "text": "Introducing Woofer",
            "title": "Introduction"
        },
        {
            "location": "/introduction/#introducing-woofer",
            "text": "",
            "title": "Introducing Woofer"
        },
        {
            "location": "/discover-logs/",
            "text": "Discover logs in Kibana\n\n\nThis video shows you how to create discover views in Kibana to explore Java & access logs pushed by Woofer.",
            "title": "Discover Logs"
        },
        {
            "location": "/discover-logs/#discover-logs-in-kibana",
            "text": "This video shows you how to create discover views in Kibana to explore Java & access logs pushed by Woofer.",
            "title": "Discover logs in Kibana"
        },
        {
            "location": "/incident-analysis/",
            "text": "Incident Analysis with ELK\n\n\nThis tutorial shows how incredibly code & libs used in Woofer will help you in your incident analysis using Kibana.\n\n\n\n\n\n\n\nGenerate an internal error\n\n\n\n\nLogin to Woofer\n,\n\n\nPost a woof that contains the ''err:back'' text,\n\n\nYou should get an error page:\n\n\n\nCopy the error unique ID (\n#d7506d00-99f2c6eb90682\n in above example).\n\n\n\n\n\n\nRetrieve the complete stack trace\n\n\n\n\nGo to \nKibana\n,\n\n\nOpen the \nWoofer Java logs\n saved search,\n\n\n\nPaste the error unique ID in the search input field and press \nRETURN\n,\n\n\n\nYou should get the originating error. Expand it, and you get the complete stack trace !\n\n\n\n\n\n\n\nFilter logs from the request\n\n\nIf the stack trace is not enough to analyze the issue and if you need to know what was processed previously during the request, you may filter logs\nby \nX-B3-TraceId\n (unique \ntreatment\n ID generated by \nSpring Cloud Sleuth\n).\n\n\n\n\nclick the \n+\n magnifier icon on the \nX-B3-TraceId\n field: that will add the \nX-B3-TraceId: \"xxxxxxxx\"\n to the current query,\n\n\n\nclear the Kibana search input field and press \nRETURN\n,\n\n\nYou should now see ALL Java logs holding this trace ID (i.e. all logs produced during the processing of this treatment).\nBy the way, notice in the \n@app\n column that traces originate both from \nwoofer-webfront\n and \nwoofer-backend\n components, \nfor the same trace\n...\n\n\n\n\n\n\n\nRetrieve the access log(s)\n\n\nLet's notice that - thanks to our logging configuration - the \nX-B3-TraceId\n is also logged in access logs: you can also find the \naccess logs with complete details if required.\n\n\nHere is how to retrieve it from previous step:\n\n\n\n\npin the \nX-B3-TraceId: \"xxxxxxxx\"\n filter,\n\n\nOpen the \nWoofer access logs\n saved search,\n\n\nYou should now see all access logs from every component with this trace ID:\n\n\n\n\n\nNOTE: Actually we get only the access log from \nwoofer-backend\n because - for technical reasons - we could not have the \nwoofer-webfront\n embedded \nTomcat catch the original \nX-B3-TraceId\n. Only subsequent Tomcats do...\n\n\n\n\nFilter logs by the session or by user\n\n\nSimilarly to filtering logs by \nX-B3-TraceId\n, you may also filter them by \nsessionId\n (to analyze the complete user activity during his JEE session),\nor even by \nuserId\n (complete user activity over time).",
            "title": "Incident Analysis"
        },
        {
            "location": "/incident-analysis/#incident-analysis-with-elk",
            "text": "This tutorial shows how incredibly code & libs used in Woofer will help you in your incident analysis using Kibana.",
            "title": "Incident Analysis with ELK"
        },
        {
            "location": "/incident-analysis/#generate-an-internal-error",
            "text": "Login to Woofer ,  Post a woof that contains the ''err:back'' text,  You should get an error page:  Copy the error unique ID ( #d7506d00-99f2c6eb90682  in above example).",
            "title": "Generate an internal error"
        },
        {
            "location": "/incident-analysis/#retrieve-the-complete-stack-trace",
            "text": "Go to  Kibana ,  Open the  Woofer Java logs  saved search,  Paste the error unique ID in the search input field and press  RETURN ,  You should get the originating error. Expand it, and you get the complete stack trace !",
            "title": "Retrieve the complete stack trace"
        },
        {
            "location": "/incident-analysis/#filter-logs-from-the-request",
            "text": "If the stack trace is not enough to analyze the issue and if you need to know what was processed previously during the request, you may filter logs\nby  X-B3-TraceId  (unique  treatment  ID generated by  Spring Cloud Sleuth ).   click the  +  magnifier icon on the  X-B3-TraceId  field: that will add the  X-B3-TraceId: \"xxxxxxxx\"  to the current query,  clear the Kibana search input field and press  RETURN ,  You should now see ALL Java logs holding this trace ID (i.e. all logs produced during the processing of this treatment).\nBy the way, notice in the  @app  column that traces originate both from  woofer-webfront  and  woofer-backend  components,  for the same trace ...",
            "title": "Filter logs from the request"
        },
        {
            "location": "/incident-analysis/#retrieve-the-access-logs",
            "text": "Let's notice that - thanks to our logging configuration - the  X-B3-TraceId  is also logged in access logs: you can also find the \naccess logs with complete details if required.  Here is how to retrieve it from previous step:   pin the  X-B3-TraceId: \"xxxxxxxx\"  filter,  Open the  Woofer access logs  saved search,  You should now see all access logs from every component with this trace ID:   NOTE: Actually we get only the access log from  woofer-backend  because - for technical reasons - we could not have the  woofer-webfront  embedded \nTomcat catch the original  X-B3-TraceId . Only subsequent Tomcats do...",
            "title": "Retrieve the access log(s)"
        },
        {
            "location": "/incident-analysis/#filter-logs-by-the-session-or-by-user",
            "text": "Similarly to filtering logs by  X-B3-TraceId , you may also filter them by  sessionId  (to analyze the complete user activity during his JEE session),\nor even by  userId  (complete user activity over time).",
            "title": "Filter logs by the session or by user"
        }
    ]
}